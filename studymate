 =============================
# 1. Install dependencies
# =============================
!pip install ibm-watsonx-ai PyPDF2 python-docx

# =============================
# 2. Imports
# =============================
import PyPDF2
import docx
from ibm_watsonx_ai import APIClient
from ibm_watsonx_ai.foundation_models import ModelInference
from ibm_watsonx_ai.wml_client_error import WMLClientError
from google.colab import files
import time

# =============================
# 3. Credentials (enter securely)
# =============================
print("ğŸ” Please provide your IBM Watsonx.ai credentials:")
API_KEY = input("ğŸ”‘ IBM Cloud API Key: ")
API_URL = input("ğŸŒ IBM Cloud URL (e.g. https://us-south.ml.cloud.ibm.com): ")
PROJECT_ID = input("ğŸ“‚ Watsonx.ai Project ID: ")

credentials = {"apikey": API_KEY, "url": API_URL}

print("\nâ³ Authenticating...")
try:
    client = APIClient(credentials=credentials, project_id=PROJECT_ID)
    print("âœ… Authentication successful!\n")
except WMLClientError as e:
    print("âŒ Authentication failed. Please check your API Key, URL, and Project ID.")
    raise

# =============================
# 4. File Upload
# =============================
print("ğŸ“¤ Upload a PDF, DOCX, or TXT file:")
uploaded = files.upload()
file_path = list(uploaded.keys())[0]  # Take first uploaded file
print(f"ğŸ“„ File uploaded: {file_path}\n")

# =============================
# 5. File Loaders
# =============================
def load_pdf_text(path):
    text = ""
    with open(path, "rb") as f:
        reader = PyPDF2.PdfReader(f)
        for page in reader.pages:
            text += page.extract_text() or ""
    return text

def load_docx_text(path):
    doc = docx.Document(path)
    return "\n".join([para.text for para in doc.paragraphs])

def load_txt_text(path):
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def load_document(path):
    if path.lower().endswith(".pdf"):
        return load_pdf_text(path)
    elif path.lower().endswith(".docx"):
        return load_docx_text(path)
    elif path.lower().endswith(".txt"):
        return load_txt_text(path)
    else:
        raise ValueError("âš ï¸ Unsupported file type. Please upload PDF, DOCX, or TXT.")

# =============================
# 6. Initialize Granite Model
# =============================
model_id = "ibm/granite-13b-instruct-v2"
inference = ModelInference(model_id=model_id, client=client, project_id=PROJECT_ID)

def run_prompt(prompt, task_name=""):
    print(f"\nğŸ“ Generating {task_name} ...")
    try:
        result = inference.generate_text(
            prompt=prompt,
            max_new_tokens=500,
            temperature=0.2
        )
        time.sleep(1)  # Smooth output transition
        return result["results"][0].get("generated_text", "").strip()
    except Exception as e:
        return f"âŒ Error during {task_name}: {str(e)}"

# =============================
# 7. Process Document
# =============================
print("ğŸ“š Reading document...")
document_text = load_document(file_path)
print("âœ… Document loaded successfully!\n")

summary_prompt = f"Summarize this document:\n\n{document_text}\n\nSummary:"
qa_prompt = f"From the following document, generate 5 key questions with their answers:\n\n{document_text}\n\nQ&A:"
cheatsheet_prompt = f"Create a concise cheat sheet with bullet points from this document:\n\n{document_text}\n\nCheat Sheet:"

summary = run_prompt(summary_prompt, "Summary")
qa = run_prompt(qa_prompt, "Q&A")
cheatsheet = run_prompt(cheatsheet_prompt, "Cheat Sheet")

# =============================
# 8. Display Results
# =============================
print("\n" + "="*40)
print("ğŸ“Œ DOCUMENT INSIGHTS")
print("="*40)

print("\nğŸ” SUMMARY:\n")
print(summary if summary else "âš ï¸ No summary generated.")

print("\nâ“ Q&A:\n")
print(qa if qa else "âš ï¸ No Q&A generated.")

print("\nğŸ“‹ CHEAT SHEET:\n")
print(cheatsheet if cheatsheet else "âš ï¸ No cheat sheet generated.")
print("\nâœ… Done!")
